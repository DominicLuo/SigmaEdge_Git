import requests
import pandas as pd
import os
import yfinance as yf
from bs4 import BeautifulSoup
from io import StringIO
# è·å–é¡¹ç›®æ ¹ç›®å½•
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_RAW_DIR = os.path.join(BASE_DIR, "data", "raw")

def clean_ticker_symbols(tickers):
    """ä¿®æ­£ Yahoo Finance è¯†åˆ«çš„ S&P 500 ä»£ç æ ¼å¼"""
    cleaned_tickers = [ticker.replace(".", "-") for ticker in tickers]
    return cleaned_tickers

def get_sp500_tickers():
    """ä» Wikipedia è·å– S&P 500 æˆåˆ†è‚¡åˆ—è¡¨"""
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # è§£æè¡¨æ ¼
    table = soup.find("table", {"id": "constituents"})
    if table is None:
        print("âŒ Error: æ²¡æœ‰æ‰¾åˆ° S&P 500 æˆåˆ†è‚¡è¡¨æ ¼ï¼Œå¯èƒ½ Wikipedia é¡µé¢ç»“æ„å˜äº†")
        return []

    # ä¿®æ­£ FutureWarningï¼Œä½¿ç”¨ StringIO åŒ…è£… HTML
    df = pd.read_html(StringIO(str(table)))[0]

    # æå–è‚¡ç¥¨ä»£ç 
    tickers = df["Symbol"].tolist()
    tickers_file = os.path.join(DATA_RAW_DIR, "sp500_tickers.csv")
    df.to_csv(tickers_file, index=False)

    print(f"âœ… æˆåŠŸè·å– {len(tickers)} åª S&P 500 è‚¡ç¥¨")
    return tickers


def download_sp500_data(start="2010-01-01", end="2025-01-01"):
    """ä¸‹è½½ S&P 500 æˆåˆ†è‚¡çš„å†å²ä»·æ ¼æ•°æ®"""
    tickers = get_sp500_tickers()
    if not tickers:
        print("âŒ Error: æœªèƒ½è·å– S&P 500 è‚¡ç¥¨åˆ—è¡¨")
        return

    print(f"ğŸ“Š æ­£åœ¨ä¸‹è½½ {len(tickers)} åª S&P 500 è‚¡ç¥¨æ•°æ®...")

    # **è·å–æ•°æ®**
    sp500_data = yf.download(tickers, start=start, end=end, group_by="ticker", auto_adjust=False)

    # **æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º**
    if sp500_data.empty:
        print("âŒ Error: ä¸‹è½½çš„ S&P 500 æ•°æ®ä¸ºç©ºï¼å¯èƒ½æ˜¯ API é™åˆ¶æˆ–è‚¡ç¥¨ä»£ç é”™è¯¯")
        return

    # âœ… è§£å†³ MultiIndex é—®é¢˜
    if isinstance(sp500_data.columns, pd.MultiIndex):
        sp500_data = sp500_data.xs("Adj Close", axis=1, level=1)  # æå– "Adj Close"

    # **æ‰“å°æ•°æ®ç»“æ„**
    print("ğŸ“Š S&P 500 æ•°æ®åˆ—å:", sp500_data.columns)

    # **æ£€æŸ¥ `Adj Close` æ˜¯å¦å­˜åœ¨**
    if isinstance(sp500_data.columns, pd.MultiIndex):
        try:
            sp500_data = sp500_data[("Adj Close", tickers)]
        except KeyError:
            print("âš ï¸ Warning: 'Adj Close' not found in MultiIndex columns. Saving full dataset.")
            sp500_data.to_csv(os.path.join(DATA_RAW_DIR, "sp500_data_prices .csv"))
            return
    elif "Adj Close" in sp500_data.columns:
        sp500_data = sp500_data["Adj Close"]
    else:
        print("âš ï¸ Warning: 'Adj Close' column not found! Saving full dataset for debugging.")
        sp500_data.to_csv(os.path.join(DATA_RAW_DIR, "sp500_data_prices.csv"))
        return

    # **ä¿å­˜æ•°æ®**
    os.makedirs(DATA_RAW_DIR, exist_ok=True)
    sp500_data.to_csv(os.path.join(DATA_RAW_DIR, "sp500_stock_prices.csv"))
    print("âœ… S&P 500 è‚¡ç¥¨æ•°æ®ä¸‹è½½å®Œæˆ")


def download_vix_data(start="2010-01-01", end="2025-01-01"):
    """ä¸‹è½½ VIXï¼ˆææ…ŒæŒ‡æ•°ï¼‰æ•°æ®"""
    vix_data = yf.download("^VIX", start=start, end=end, auto_adjust=False)

    # **æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º**
    if vix_data.empty:
        print("âŒ Error: No VIX data downloaded! Check ticker symbol or API limit.")
        return

    # **æ‰“å°è¿”å›çš„æ•°æ®æ ¼å¼**
    print("ğŸ“Š VIX æ•°æ®åˆ—å:", vix_data.columns)

    # **å¤„ç† MultiIndex**
    if isinstance(vix_data.columns, pd.MultiIndex):
        try:
            vix_data = vix_data[("Adj Close", "^VIX")]
        except KeyError:
            print("âš ï¸ Warning: 'Adj Close' not found in MultiIndex columns. Saving full dataset.")
            vix_data.to_csv("data/raw/vix_data_full.csv")
            return
    elif "Adj Close" in vix_data.columns:
        vix_data = vix_data["Adj Close"]
    else:
        print("âš ï¸ Warning: 'Adj Close' column not found! Saving full dataset for debugging.")
        vix_data.to_csv("data/raw/vix_data_full.csv")
        return

    # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
    os.makedirs(DATA_RAW_DIR, exist_ok=True)

    # **ä¿å­˜æ•°æ®**
    vix_data.to_csv(os.path.join(DATA_RAW_DIR, "vix_data.csv"))
    print("âœ… VIX æ•°æ®ä¸‹è½½å®Œæˆ")



if __name__ == "__main__":
    get_sp500_tickers()
    download_sp500_data()
    download_vix_data()
